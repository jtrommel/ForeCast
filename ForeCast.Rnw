\documentclass[a4paper,11pt]{article}
\usepackage{graphicx} % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[total={424pt,600pt},top=100pt,left=90pt]{geometry} % instelling van de paginaindeling
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage{layout} % Gebruik in het begin om de layout-elementen van het document te verifiÃ«ren
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\title{Forecasting methods}
\author{Jan Trommelmans}

\begin{document}
\date{}
\SweaveOpts{concordance=TRUE,prefix.string=ForeCast}
\maketitle

<<>>=
library(tidyverse)
library(lubridate)
library(gridExtra)
@

\section{Forecasting methods}

\url{https://grisha.org/blog/2016/01/29/triple-exponential-smoothing-forecasting/}

\subsection{Start series}
<<label=basis,fig=TRUE,include=FALSE, echo=TRUE>>=
x <- c(1:7)
series.1 <- c(3, 10, 12, 13, 12, 10, 12)
serie <- data.frame(x=x,y=series.1)
ggplot(data=serie) + geom_point(aes(x=x, y=y))
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-basis}
\captionof{figure}{start series}
\label{fig:basis}
\end{center}

\subsection{Naive method}

$ \hat{y}_{i} = y_{i-1} $

<<label=naive,fig=TRUE,include=FALSE, echo=TRUE>>=
serie.naive <- serie
serie.naive[nrow(serie.naive)+1,] <- c(nrow(serie.naive)+1,0)
serie.naive$yhat <- NA
for (i in (2:nrow(serie.naive))) {
  serie.naive$yhat[i] <- serie.naive$y[i-1]
}
ggplot(data=serie.naive,aes(x=x)) + geom_point(aes(y=y),colour="black") + geom_point(aes(y=yhat),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-naive}
\captionof{figure}{Naive}
\label{fig:naive}
\end{center}

\subsection{Simple average}

$ \hat{y}_{i} = \frac{1}{i-1}\sum_{j=1}^{j=i-1}y_{j} $

<<label=sa,fig=TRUE,include=FALSE, echo=TRUE>>=
serie.sa <- serie
serie.sa[nrow(serie.sa)+1,] <- c(nrow(serie.sa)+1,NA)
serie.sa$cumsum <- cumsum(serie.sa$y)
for (i in (2:nrow(serie.sa))) {
  serie.sa$yhat[i] <- serie.sa$cumsum[i-1]/serie.sa$x[i-1]
}
ggplot(data=serie.sa,aes(x=x)) + geom_point(aes(y=y),colour="black") + geom_point(aes(y=yhat),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-sa}
\captionof{figure}{Simple average}
\label{fig:sa}
\end{center}

\subsection{Moving average with size n}

n=3

$ \hat{y}_{i} = \frac{1}{n}\sum_{j=i-n}^{j=i-1}y_{j} $

<<label=ma,fig=TRUE,include=FALSE, echo=TRUE>>=
n <- 3
serie.ma <- serie
serie.ma[nrow(serie.ma)+1,] <- c(nrow(serie.ma)+1,NA)
for (i in ((n+1):nrow(serie.ma))) {
  som <- 0
  for (j in (1:n)) {
    som <- som + serie.ma$y[i-j]
  } 
  serie.ma$yhat[i] <- som/n
}
ggplot(data=serie.ma,aes(x=x)) + geom_point(aes(y=y),colour="black") + geom_point(aes(y=yhat),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-ma}
\captionof{figure}{Moving average (n=3)}
\label{fig:ma}
\end{center}

\subsection{Weighted Moving average with size n and weighing vector}

n=4
Weighing vector = [0.1 0.2 0.3 0.4] with $\sum_{k=1}^{k=n}w_{k}=1 $

$ \hat{y}_{i} = \sum_{j=1}^{j=n}y_{i-j}*w_{n-j} $

<<label=wma,fig=TRUE,include=FALSE, echo=TRUE>>=
n <- 4
w <- c(0.1, 0.2, 0.3, 0.4)
serie.wma <- serie
serie.wma[nrow(serie.wma)+1,] <- c(nrow(serie.wma)+1,NA)
serie.wma$yhat <- NA
for (i in ((n+1):nrow(serie.wma))) {
  serie.wma$yhat[i] <- 0
  for (j in (1:n)) {
    serie.wma$yhat[i] <- serie.wma$yhat[i] + serie.wma$y[i-j]*w[n-j+1]
  } 
}
ggplot(data=serie.wma,aes(x=x)) + geom_point(aes(y=y),colour="black") + geom_point(aes(y=yhat),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-wma}
\captionof{figure}{Weighted Moving Average (n=4) (w=(0.1 0.2 0.3 0.4))}
\label{fig:wma}
\end{center}

\section{Exponential smoothing}

\subsection{Single exponential smoothing}

You use all former datapoints with a steadily decreasing weight: e.g. 

weighing vector=$\left[  0.9 \quad 0.9^{2} \quad 0.9^{3} \ldots \right]$

However the sum of all the weight should be 1. This is not the case. Poisson, Holt and Roberts found a solution by calculating the expected value in a recursive way:

$ \hat{y}_{i} = \alpha y_{i} + \left( 1-\alpha \right)\hat{y}_{i-1} $

$\alpha$ is the importance that is given to the present observed value. High values of $\alpha$ mean that the influence of former data points fades quickly. $\alpha$ is called the ''smoothing force" or ''smoothing coefficient" but a better name would be ''memory decay rate".

<<label=ses,fig=TRUE,include=FALSE, echo=TRUE>>=
serie.ses <- serie
serie.ses[nrow(serie.ses)+1,] <- c(nrow(serie.ses)+1,NA)
for (k in c(1:2)) {
if (k==1) {
  alpha <- 0.1
  serie.ses$yhat01 <- NA
  serie.ses$yhat01[1] <- serie.ses$y[1]
  for (i in (2:nrow(serie.ses))) {
    serie.ses$yhat01[i] <- alpha*serie.ses$y[i]+(1-alpha)*serie.ses$yhat01[i-1]
    }
  } else {
  alpha <- 0.9
  serie.ses$yhat09 <- NA
  serie.ses$yhat09[1] <- serie.ses$y[1]
  for (i in (2:nrow(serie.ses))) {
    serie.ses$yhat09[i] <- alpha*serie.ses$y[i]+(1-alpha)*serie.ses$yhat09[i-1]
    }
  }
} 
ggplot(data=serie.ses,aes(x=x)) + 
  geom_point(aes(y=y),colour="black") + 
  geom_point(aes(y=yhat01),colour="green") +
  geom_point(aes(y=yhat09),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-ses}
\captionof{figure}{Single Exponential Smoothing (alpha=0.1 green, alpha=0.9 red)}
\label{fig:ses}
\end{center}

\subsection{Double Exponential Smoothing}

In the naive method we equated the next expected value to the present observed value:\\

$ \hat{y}_{i}=y_{i-1} $\\

We can improve on that by using the slope (trend) in the datapoints.

If the slope is $ b_{i}=y_{i}-y_{i-1} $ then a better estimate of the next expected value could be\\

$ \hat{y}_{i}=y_{i-1} + b_{i} $

Instead of working with the observed values $y_{i}$ we work with calculated values, called levels, $l_{i}$. Both the levels and the slopes (so ''Double") can be ''exponentialy smoothed":

\begin{align}
l_{i}&=\alpha y_{i}+\left( 1-\alpha  \right) \left( l_{i-1}+b_{i-1}  \right) \\
b_{i}&=\beta \left( l_{i} - l_{i-1} \right) + \left( 1-\beta  \right)b_{i-1} \\
\hat{y}_{i+1}&=l_{i}+b_{i}
\end{align}

<<label=des,fig=TRUE,include=FALSE, echo=TRUE>>=
serie.des <- serie
serie.des[nrow(serie.des)+1,] <- c(nrow(serie.des)+1,NA)
alpha <- 0.9
beta <- 0.9
serie.des$level <- NA
serie.des$slope <- NA
serie.des$yhat <- NA
serie.des$level[1] <- serie.des$y[1]
serie.des$slope[1] <- 0
serie.des$yhat[1] <- serie.des$y[1]
for (i in (2:nrow(serie.des))) {
  if (i==2) {
    new.level <- serie.des$y[i]
    new.slope <- serie.des$y[i]-serie.des$y[i-1]
  } else {
  if (i >= nrow(serie.des)) {
    yvalue <- serie.des$yhat[i-1]
  } else {
    yvalue <- serie.des$y[i]
  }
  last.level <- serie.des$level[i-1]
  last.slope <- serie.des$slope[i-1]
  new.level <- alpha*yvalue + (1 - alpha)*(last.level + last.slope)
  new.slope <- beta*(new.level - last.level) + (1 - beta)*last.slope
  }
  serie.des$yhat[i] <- new.level + new.slope
  serie.des$level[i] <- new.level
  serie.des$slope[i] <- new.slope
}
ggplot(data=serie.des,aes(x=x)) + 
  geom_point(aes(y=y),colour="black") + 
  geom_point(aes(y=yhat),colour="red")
@

\begin{center}
\includegraphics[width=0.5\textwidth]{ForeCast-des}
\captionof{figure}{Double Exponential Smoothing (alpha=0.9, beta=0.9)}
\label{fig:des}
\end{center}

Same results as Trubetskoy and when you use the HoltWinters function maar verschoven in de tijd.

<<>>=
serie.des$HW <- serie.des$y
fit <- HoltWinters(serie$y, alpha=0.9, beta=0.9, gamma=FALSE)
serie.des$HW[3:7] <- as.data.frame(fit$fitted)[,1]
@

\subsection{Triple Exponential Smoothing}

Terminology:
\begin{itemize}
  \item Season: if a series appears to be repetitive at regular intervals, it is called \emph{seasonal}. \textbf{Seasonality is a precondition for the use of Holt-Winters!}
  \item Season length: L = number of data points after which a new season starts
  \item Seasonal component: an aditional deviation from level + trend. There is a seasonal component for every point in a season.
\end{itemize}

Triple exponential smoothing applies an exponential smoothing to the seasonal components in addition to level and trend. The smoothing is applied across seasons e.g. the seasonal component of the third point into the season will be exponentialy smoothed with the third point of last season, the third component of two seasons ago etc.
\end{document}